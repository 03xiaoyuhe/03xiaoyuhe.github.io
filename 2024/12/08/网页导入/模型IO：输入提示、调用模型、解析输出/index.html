<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
<link rel="stylesheet" href="/css/custom.css">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="你好，我是黄佳，欢迎来到 LangChain 实战课！ 从这节课开始，我们将对 LangChain 中的六大核心组件一一进行详细的剖析。 模型，位于 LangChain 框架的最底层，它是基于语言模型构建的应用的核心元素，因为所谓 LangChain 应用开发，就是以 LangChain 作为框架，通过 API 调用大模型来解决具体问题的过程。 可以说，整个 LangChain 框架的逻辑都是由">
<meta property="og:type" content="article">
<meta property="og:title" content="O3xiaoyuhe">
<meta property="og:url" content="http://example.com/2024/12/08/%E7%BD%91%E9%A1%B5%E5%AF%BC%E5%85%A5/%E6%A8%A1%E5%9E%8BIO%EF%BC%9A%E8%BE%93%E5%85%A5%E6%8F%90%E7%A4%BA%E3%80%81%E8%B0%83%E7%94%A8%E6%A8%A1%E5%9E%8B%E3%80%81%E8%A7%A3%E6%9E%90%E8%BE%93%E5%87%BA/index.html">
<meta property="og:site_name" content="O3xiaoyuhe">
<meta property="og:description" content="你好，我是黄佳，欢迎来到 LangChain 实战课！ 从这节课开始，我们将对 LangChain 中的六大核心组件一一进行详细的剖析。 模型，位于 LangChain 框架的最底层，它是基于语言模型构建的应用的核心元素，因为所谓 LangChain 应用开发，就是以 LangChain 作为框架，通过 API 调用大模型来解决具体问题的过程。 可以说，整个 LangChain 框架的逻辑都是由">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/487e3a24b3324a279309b90adce319ec~tplv-k3u1fbpfcp-jj-mark:2268:0:0:0:q75.awebp#?w=1965&amp;h=1363&amp;s=498342&amp;e=png&amp;b=ffffff">
<meta property="og:image" content="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ffb488f5f695467bb994245df8d947c1~tplv-k3u1fbpfcp-jj-mark:2268:0:0:0:q75.awebp#?w=4000&amp;h=1536&amp;s=298807&amp;e=png&amp;b=eefcf1">
<meta property="og:image" content="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b336202a59124ff69d1ea0184e5321b3~tplv-k3u1fbpfcp-jj-mark:2268:0:0:0:q75.awebp#?w=1704&amp;h=854&amp;s=302708&amp;e=png&amp;b=fffafa">
<meta property="og:image" content="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8eb5d4eb72c2439397fba4d0fa5450c4~tplv-k3u1fbpfcp-jj-mark:2268:0:0:0:q75.awebp#?w=1032&amp;h=97&amp;s=6999&amp;e=png&amp;b=faf9f9">
<meta property="article:published_time" content="2024-12-08T12:29:01.365Z">
<meta property="article:modified_time" content="2024-11-18T11:04:15.259Z">
<meta property="article:author" content="听">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/487e3a24b3324a279309b90adce319ec~tplv-k3u1fbpfcp-jj-mark:2268:0:0:0:q75.awebp#?w=1965&amp;h=1363&amp;s=498342&amp;e=png&amp;b=ffffff">

<link rel="canonical" href="http://example.com/2024/12/08/%E7%BD%91%E9%A1%B5%E5%AF%BC%E5%85%A5/%E6%A8%A1%E5%9E%8BIO%EF%BC%9A%E8%BE%93%E5%85%A5%E6%8F%90%E7%A4%BA%E3%80%81%E8%B0%83%E7%94%A8%E6%A8%A1%E5%9E%8B%E3%80%81%E8%A7%A3%E6%9E%90%E8%BE%93%E5%87%BA/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title> | O3xiaoyuhe</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">O3xiaoyuhe</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/12/08/%E7%BD%91%E9%A1%B5%E5%AF%BC%E5%85%A5/%E6%A8%A1%E5%9E%8BIO%EF%BC%9A%E8%BE%93%E5%85%A5%E6%8F%90%E7%A4%BA%E3%80%81%E8%B0%83%E7%94%A8%E6%A8%A1%E5%9E%8B%E3%80%81%E8%A7%A3%E6%9E%90%E8%BE%93%E5%87%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="听">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="O3xiaoyuhe">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-12-08 20:29:01" itemprop="dateCreated datePublished" datetime="2024-12-08T20:29:01+08:00">2024-12-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-11-18 19:04:15" itemprop="dateModified" datetime="2024-11-18T19:04:15+08:00">2024-11-18</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>你好，我是黄佳，欢迎来到 LangChain 实战课！</p>
<p>从这节课开始，我们将对 LangChain 中的六大核心组件一一进行详细的剖析。</p>
<p>模型，位于 LangChain 框架的最底层，它是基于语言模型构建的应用的<strong>核心元素</strong>，因为所谓 LangChain 应用开发，就是以 LangChain 作为框架，通过 API 调用大模型来解决具体问题的过程。</p>
<p>可以说，整个 LangChain 框架的逻辑都是由 LLM 这个发动机来驱动的。没有模型，LangChain 这个框架也就失去了它存在的意义。那么这节课我们就详细讲讲模型，最后你会收获一个能够自动生成鲜花文案的应用程序。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/487e3a24b3324a279309b90adce319ec~tplv-k3u1fbpfcp-jj-mark:2268:0:0:0:q75.awebp#?w=1965&amp;h=1363&amp;s=498342&amp;e=png&amp;b=ffffff" alt=""></p>
<h2 id="Model-I-O">Model I/O</h2>
<p>我们可以把对模型的使用过程拆解成三块，分别是<strong>输入提示</strong>（对应图中的 Format）、<strong>调用模型</strong>（对应图中的 Predict）和<strong>输出解析</strong>（对应图中的 Parse）。这三块形成了一个整体，因此在 LangChain 中这个过程被统称为 <strong>Model I/O</strong>（Input/Output）。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ffb488f5f695467bb994245df8d947c1~tplv-k3u1fbpfcp-jj-mark:2268:0:0:0:q75.awebp#?w=4000&amp;h=1536&amp;s=298807&amp;e=png&amp;b=eefcf1" alt=""></p>
<p>在模型 I/O 的每个环节，LangChain 都为咱们提供了模板和工具，快捷地形成调用各种语言模型的接口。</p>
<ol>
<li class="lvl-4">
<p><strong>提示模板</strong>：使用模型的第一个环节是把提示信息输入到模型中，你可以创建 LangChain 模板，根据实际需求动态选择不同的输入，针对特定的任务和应用调整输入。</p>
</li>
<li class="lvl-4">
<p><strong>语言模型</strong>：LangChain 允许你通过通用接口来调用语言模型。这意味着无论你要使用的是哪种语言模型，都可以通过同一种方式进行调用，这样就提高了灵活性和便利性。</p>
</li>
<li class="lvl-4">
<p><strong>输出解析</strong>：LangChain 还提供了从模型输出中提取信息的功能。通过输出解析器，你可以精确地从模型的输出中获取需要的信息，而不需要处理冗余或不相关的数据，更重要的是还可以把大模型给回的非结构化文本，转换成程序可以处理的结构化数据。</p>
</li>
</ol>
<p>下面我们用示例的方式来深挖一下这三个环节。先来看看 LangChain 中提示模板的构建。</p>
<h2 id="提示模板">提示模板</h2>
<p>语言模型是个无穷无尽的宝藏，人类的知识和智慧，好像都封装在了这个 “魔盒” 里面了。但是，怎样才能解锁其中的奥秘，那可就是仁者见仁智者见智了。所以，现在 “提示工程” 这个词特别流行，所谓 Prompt Engineering，就是专门研究对大语言模型的提示构建。</p>
<p>我的观点是，使用大模型的场景千差万别，因此肯定不存在那么一两个神奇的模板，能够骗过所有模型，让它总能给你最想要的回答。然而，好的提示（其实也就是好的问题或指示啦），肯定能够让你在调用语言模型的时候事半功倍。</p>
<p>那其中的具体原则，不外乎吴恩达老师在他的<a href="https://link.juejin.cn/?target=https%3A%2F%2Flearn.deeplearning.ai%2Flogin%3Fredirect_course%3Dchatgpt-prompt-eng" title="https://learn.deeplearning.ai/login?redirect_course=chatgpt-prompt-eng">提示工程课程</a>中所说的：</p>
<ol>
<li class="lvl-4">
<p>给予模型清晰明确的指示</p>
</li>
<li class="lvl-4">
<p>让模型慢慢地思考</p>
</li>
</ol>
<p>说起来很简单，对吧？是的，道理总是简单，但是如何具体实践这些原则，又是个大问题。让我从创建一个简单的 LangChain 提示模板开始。</p>
<p>这里，我们希望为销售的每一种鲜花生成一段简介文案，那么每当你的员工或者顾客想了解某种鲜花时，调用该模板就会生成适合的文字。</p>
<p>这个提示模板的生成方式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 导入LangChain中的提示模板</span><br><span class="line">from langchain.prompts import PromptTemplate</span><br><span class="line"># 创建原始模板</span><br><span class="line">template = &quot;&quot;&quot;您是一位专业的鲜花店文案撰写员。\n</span><br><span class="line">对于售价为 &#123;price&#125; 元的 &#123;flower_name&#125; ，您能提供一个吸引人的简短描述吗？</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"># 根据原始模板创建LangChain提示模板</span><br><span class="line">prompt = PromptTemplate.from_template(template) </span><br><span class="line"># 打印LangChain提示模板的内容</span><br><span class="line">print(prompt)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>提示模板的具体内容如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">input_variables=[&#x27;flower_name&#x27;, &#x27;price&#x27;] </span><br><span class="line">output_parser=None partial_variables=&#123;&#125; </span><br><span class="line">template=&#x27;/\n您是一位专业的鲜花店文案撰写员。</span><br><span class="line">\n对于售价为 &#123;price&#125; 元的 &#123;flower_name&#125; ，您能提供一个吸引人的简短描述吗？\n&#x27;</span><br><span class="line">template_format=&#x27;f-string&#x27; </span><br><span class="line">validate_template=True</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在这里，所谓 “模板” 就是一段描述某种鲜花的文本格式，它是一个 f-string，其中有两个变量 {flower_name} 和 {price} 表示花的名称和价格，这两个值是模板里面的占位符，在实际使用模板生成提示时会被具体的值替换。</p>
<p>代码中的 from_template 是一个类方法，它允许我们直接从一个字符串模板中创建一个 PromptTemplate 对象。打印出这个 PromptTemplate 对象，你可以看到这个对象中的信息包括输入的变量（在这个例子中就是 <code>flower_name</code> 和 <code>price</code>）、输出解析器（这个例子中没有指定）、模板的格式（这个例子中为<code>'f-string'</code>）、是否验证模板（这个例子中设置为 <code>True</code>）。</p>
<p>因此 PromptTemplate 的 from_template 方法就是将一个原始的模板字符串转化为一个更丰富、更方便操作的 PromptTemplate 对象，这个对象就是 LangChain 中的提示模板。LangChain 提供了多个类和函数，也<strong>为各种应用场景设计了很多内置模板，使构建和使用提示变得容易</strong>。我们下节课还会对提示工程的基本原理和 LangChain 中的各种提示模板做更深入的讲解。</p>
<p>下面，我们将会使用这个刚刚构建好的提示模板来生成提示，并把提示输入到大语言模型中。</p>
<h2 id="语言模型"><strong>语言模型</strong></h2>
<p>LangChain 中支持的模型有三大类。</p>
<ol>
<li class="lvl-4">
<p>大语言模型（LLM） ，也叫 Text Model，这些模型将文本字符串作为输入，并返回文本字符串作为输出。Open AI 的 text-davinci-003、Facebook 的 LLaMA、ANTHROPIC 的 Claude，都是典型的 LLM。</p>
</li>
<li class="lvl-4">
<p>聊天模型（Chat Model），主要代表 Open AI 的 ChatGPT 系列模型。这些模型通常由语言模型支持，但它们的 API 更加结构化。具体来说，这些模型将聊天消息列表作为输入，并返回聊天消息。</p>
</li>
<li class="lvl-4">
<p>文本嵌入模型（Embedding Model），这些模型将文本作为输入并返回浮点数列表，也就是 Embedding。而文本嵌入模型如 OpenAI 的 text-embedding-ada-002，我们之前已经见过了。文本嵌入模型负责把文档存入向量数据库，和我们这里探讨的提示工程关系不大。</p>
</li>
</ol>
<p>然后，我们将调用语言模型，让模型帮我们写文案，并且返回文案的结果。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 设置OpenAI API Key</span><br><span class="line">import os</span><br><span class="line">os.environ[&quot;OPENAI_API_KEY&quot;] = &#x27;你的Open AI API Key&#x27;</span><br><span class="line"></span><br><span class="line"># 导入LangChain中的OpenAI模型接口</span><br><span class="line">from langchain_openai import OpenAI</span><br><span class="line"># 创建模型实例</span><br><span class="line">model = OpenAI(model_name=&#x27;gpt-3.5-turbo-instruct&#x27;)</span><br><span class="line"># 输入提示</span><br><span class="line">input = prompt.format(flower_name=[&quot;玫瑰&quot;], price=&#x27;50&#x27;)</span><br><span class="line"># 得到模型的输出</span><br><span class="line">output = model.invoke(input)</span><br><span class="line"># 打印输出内容</span><br><span class="line">print(output)  </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><code>input = prompt.format(flower_name=[&quot;玫瑰&quot;], price='50')</code> 这行代码的作用是将模板实例化，此时将 <code>&#123;flower_name&#125;</code> 替换为 <code>&quot;玫瑰&quot;</code>，<code>&#123;price&#125;</code> 替换为 <code>'50'</code>，形成了具体的提示：“您是一位专业的鲜花店文案撰写员。对于售价为 50 元的玫瑰，您能提供一个吸引人的简短描述吗？”</p>
<p>接收到这个输入，调用模型之后，得到的输出如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">让你心动！50元就可以拥有这支充满浪漫气息的玫瑰花束，让TA感受你的真心爱意。</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>复用提示模板，我们可以同时生成多个鲜花的文案。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"># 导入LangChain中的提示模板</span><br><span class="line">from langchain import PromptTemplate</span><br><span class="line"># 创建原始模板</span><br><span class="line">template = &quot;&quot;&quot;您是一位专业的鲜花店文案撰写员。\n</span><br><span class="line">对于售价为 &#123;price&#125; 元的 &#123;flower_name&#125; ，您能提供一个吸引人的简短描述吗？</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"># 根据原始模板创建LangChain提示模板</span><br><span class="line">prompt = PromptTemplate.from_template(template) </span><br><span class="line"># 打印LangChain提示模板的内容</span><br><span class="line">print(prompt)</span><br><span class="line"></span><br><span class="line"># 设置OpenAI API Key</span><br><span class="line">import os</span><br><span class="line">os.environ[&quot;OPENAI_API_KEY&quot;] = &#x27;你的Open AI API Key&#x27;</span><br><span class="line"></span><br><span class="line"># 导入LangChain中的OpenAI模型接口</span><br><span class="line">from langchain import OpenAI</span><br><span class="line"># 创建模型实例</span><br><span class="line">model = OpenAI(model_name=&#x27;gpt-3.5-turbo-instruct&#x27;)</span><br><span class="line"></span><br><span class="line"># 多种花的列表</span><br><span class="line">flowers = [&quot;玫瑰&quot;, &quot;百合&quot;, &quot;康乃馨&quot;]</span><br><span class="line">prices = [&quot;50&quot;, &quot;30&quot;, &quot;20&quot;]</span><br><span class="line"></span><br><span class="line"># 生成多种花的文案</span><br><span class="line">for flower, price in zip(flowers, prices):</span><br><span class="line">    # 使用提示模板生成输入</span><br><span class="line">    input_prompt = prompt.format(flower_name=flower, price=price)</span><br><span class="line"></span><br><span class="line">    # 得到模型的输出</span><br><span class="line">    output = model.invoke(input_prompt)</span><br><span class="line"></span><br><span class="line">    # 打印输出内容</span><br><span class="line">    print(output)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>模型的输出如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">这支玫瑰，深邃的红色，传递着浓浓的深情与浪漫，令人回味无穷！</span><br><span class="line">百合：美丽的花朵，多彩的爱恋！30元让你拥有它！</span><br><span class="line">康乃馨—20元，象征爱的祝福，送给你最真挚的祝福。</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>你也许会问我，在这个过程中，使用 LangChain 的意义究竟何在呢？我直接调用 Open AI 的 API，不是完全可以实现相同的功能吗？</p>
<p>的确如此，让我们来看看直接使用 Open AI API 来完成上述功能的代码。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import openai # 导入OpenAI</span><br><span class="line">openai.api_key = &#x27;Your-OpenAI-API-Key&#x27; # API Key</span><br><span class="line"></span><br><span class="line">prompt_text = &quot;您是一位专业的鲜花店文案撰写员。对于售价为&#123;&#125;元的&#123;&#125;，您能提供一个吸引人的简短描述吗？&quot; # 设置提示</span><br><span class="line"></span><br><span class="line">flowers = [&quot;玫瑰&quot;, &quot;百合&quot;, &quot;康乃馨&quot;]</span><br><span class="line">prices = [&quot;50&quot;, &quot;30&quot;, &quot;20&quot;]</span><br><span class="line"></span><br><span class="line"># 循环调用Text模型的Completion方法，生成文案</span><br><span class="line">for flower, price in zip(flowers, prices):</span><br><span class="line">    prompt = prompt_text.format(price, flower)</span><br><span class="line">    response = openai.completions.create(</span><br><span class="line">        engine=&quot;gpt-3.5-turbo-instruct&quot;,</span><br><span class="line">        prompt=prompt,</span><br><span class="line">        max_tokens=100</span><br><span class="line">    )</span><br><span class="line">    print(response.choices[0].text.strip()) # 输出文案</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>上面的代码是直接使用 Open AI 和带有 {} 占位符的提示语，同时生成了三种鲜花的文案。看起来也是相当简洁。</p>
<p>不过，如果你深入思考一下，你就会发现 LangChain 的优势所在。<strong>我们只需要定义一次模板，就可以用它来生成各种不同的提示</strong>。对比单纯使用 f-string 来格式化文本，这种方法更加简洁，也更容易维护。而 LangChain 在提示模板中，还整合了 output_parser、template_format 以及是否需要 validate_template 等功能。</p>
<p>更重要的是，使用 LangChain 提示模板，我们还可以很方便地把程序切换到不同的模型，而不需要修改任何提示相关的代码。</p>
<p>下面，我们用完全相同的提示模板来生成提示，并发送给 HuggingFaceHub 中的开源模型来创建文案。（注意：需要注册 HUGGINGFACEHUB_API_TOKEN）</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b336202a59124ff69d1ea0184e5321b3~tplv-k3u1fbpfcp-jj-mark:2268:0:0:0:q75.awebp#?w=1704&amp;h=854&amp;s=302708&amp;e=png&amp;b=fffafa" alt=""></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># 导入LangChain中的提示模板</span><br><span class="line">from langchain.prompts import PromptTemplate</span><br><span class="line"># 创建原始模板</span><br><span class="line">template = &quot;&quot;&quot;You are a flower shop assitiant。\n</span><br><span class="line">For &#123;price&#125; of &#123;flower_name&#125; ，can you write something for me？</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"># 根据原始模板创建LangChain提示模板</span><br><span class="line">prompt = PromptTemplate.from_template(template) </span><br><span class="line"># 打印LangChain提示模板的内容</span><br><span class="line">print(prompt)</span><br><span class="line">import os</span><br><span class="line">os.environ[&#x27;HUGGINGFACEHUB_API_TOKEN&#x27;] = &#x27;你的HuggingFace API Token&#x27;</span><br><span class="line"># 导入LangChain中的OpenAI模型接口</span><br><span class="line">from langchain_community.llms import HuggingFaceHub</span><br><span class="line"># 创建模型实例</span><br><span class="line">model= HuggingFaceHub(repo_id=&quot;google/flan-t5-large&quot;)</span><br><span class="line"># 输入提示</span><br><span class="line">input = prompt.format(flower_name=[&quot;rose&quot;], price=&#x27;50&#x27;)</span><br><span class="line"># 得到模型的输出</span><br><span class="line">output = model(input)</span><br><span class="line"># 打印输出内容</span><br><span class="line">print(output)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">i love you</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>真是一分钱一分货，当我使用较早期的开源模型 T5，得到了很粗糙的文案 “i love you”（哦，还要注意 T5 还没有支持中文的能力，我把提示文字换成英文句子，结构其实都没变）。</p>
<p>当然，这里我想要向你传递的信息是：你可以重用模板，重用程序结构，通过 LangChain 框架调用任何模型。如果你熟悉机器学习的训练流程的话，这 LangChain 是不是让你联想到 PyTorch 和 TensorFlow 这样的框架——<strong>模型可以自由选择、自主训练，而调用模型的框架往往是有章法、而且可复用的</strong>。</p>
<p>因此，使用 LangChain 和提示模板的好处是：</p>
<ol>
<li class="lvl-4">
<p>代码的可读性：使用模板的话，提示文本更易于阅读和理解，特别是对于复杂的提示或多变量的情况。</p>
</li>
<li class="lvl-4">
<p>可复用性：模板可以在多个地方被复用，让你的代码更简洁，不需要在每个需要生成提示的地方重新构造提示字符串。</p>
</li>
<li class="lvl-4">
<p>维护：如果你在后续需要修改提示，使用模板的话，只需要修改模板就可以了，而不需要在代码中查找所有使用到该提示的地方进行修改。</p>
</li>
<li class="lvl-4">
<p>变量处理：如果你的提示中涉及到多个变量，模板可以自动处理变量的插入，不需要手动拼接字符串。</p>
</li>
<li class="lvl-4">
<p>参数化：模板可以根据不同的参数生成不同的提示，这对于个性化生成文本非常有用。</p>
</li>
</ol>
<p>那我们就接着介绍模型 I/O 的最后一步，输出解析。</p>
<h2 id="输出解析"><strong>输出解析</strong></h2>
<p>LangChain 提供的解析模型输出的功能，使你能够更容易地从模型输出中获取结构化的信息，这将大大加快基于语言模型进行应用开发的效率。</p>
<p>为什么这么说呢？请你思考一下刚才的例子，你只是让模型生成了一个文案。这段文字是一段字符串，正是你所需要的。但是，在开发具体应用的过程中，很明显<strong>我们不仅仅需要文字，更多情况下我们需要的是程序能够直接处理的、结构化的数据</strong>。</p>
<p>比如说，在这个文案中，如果你希望模型返回两个字段：</p>
<ul class="lvl-0">
<li class="lvl-4">
<p>description：鲜花的说明文本</p>
</li>
<li class="lvl-4">
<p>reason：解释一下为何要这样写上面的文案</p>
</li>
</ul>
<p>那么，模型可能返回的一种结果是：</p>
<p><strong>A</strong>：“文案是：让你心动！50 元就可以拥有这支充满浪漫气息的玫瑰花束，让 TA 感受你的真心爱意。为什么这样说呢？因为爱情是无价的，50 元对应热恋中的情侣也会觉得值得。”</p>
<p>上面的回答并不是我们在处理数据时所需要的，我们需要的是一个类似于下面的 Python 字典。</p>
<p><strong>B</strong>：{description: “让你心动！50 元就可以拥有这支充满浪漫气息的玫瑰花束，让 TA 感受你的真心爱意。” ; reason: “因为爱情是无价的，50 元对应热恋中的情侣也会觉得值得。”}</p>
<p>那么从 A 的笼统言语，到 B 这种结构清晰的数据结构，如何自动实现？这就需要 LangChain 中的输出解析器上场了。</p>
<p>下面，我们就通过 LangChain 的输出解析器来重构程序，让模型有能力生成结构化的回应，同时对其进行解析，直接将解析好的数据存入 CSV 文档。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"># 导入OpenAI Key</span><br><span class="line">import os</span><br><span class="line">os.environ[&quot;OPENAI_API_KEY&quot;] = &#x27;你的OpenAI API Key&#x27;</span><br><span class="line"></span><br><span class="line"># 导入LangChain中的提示模板</span><br><span class="line">from langchain.prompts import PromptTemplate</span><br><span class="line"># 创建原始提示模板</span><br><span class="line">prompt_template = &quot;&quot;&quot;您是一位专业的鲜花店文案撰写员。</span><br><span class="line">对于售价为 &#123;price&#125; 元的 &#123;flower_name&#125; ，您能提供一个吸引人的简短描述吗？</span><br><span class="line">&#123;format_instructions&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"># 通过LangChain调用模型</span><br><span class="line">from langchain_openai import OpenAI</span><br><span class="line"># 创建模型实例</span><br><span class="line">model = OpenAI(model_name=&#x27;gpt-3.5-turbo-instruct&#x27;)</span><br><span class="line"></span><br><span class="line"># 导入结构化输出解析器和ResponseSchema</span><br><span class="line">from langchain.output_parsers import StructuredOutputParser, ResponseSchema</span><br><span class="line"># 定义我们想要接收的响应模式</span><br><span class="line">response_schemas = [</span><br><span class="line">    ResponseSchema(name=&quot;description&quot;, description=&quot;鲜花的描述文案&quot;),</span><br><span class="line">    ResponseSchema(name=&quot;reason&quot;, description=&quot;问什么要这样写这个文案&quot;)</span><br><span class="line">]</span><br><span class="line"># 创建输出解析器</span><br><span class="line">output_parser = StructuredOutputParser.from_response_schemas(response_schemas)</span><br><span class="line"></span><br><span class="line"># 获取格式指示</span><br><span class="line">format_instructions = output_parser.get_format_instructions()</span><br><span class="line"># 根据原始模板创建提示，同时在提示中加入输出解析器的说明</span><br><span class="line">prompt = PromptTemplate.from_template(prompt_template, </span><br><span class="line">                partial_variables=&#123;&quot;format_instructions&quot;: format_instructions&#125;) </span><br><span class="line"></span><br><span class="line"># 数据准备</span><br><span class="line">flowers = [&quot;玫瑰&quot;, &quot;百合&quot;, &quot;康乃馨&quot;]</span><br><span class="line">prices = [&quot;50&quot;, &quot;30&quot;, &quot;20&quot;]</span><br><span class="line"></span><br><span class="line"># 创建一个空的DataFrame用于存储结果</span><br><span class="line">import pandas as pd</span><br><span class="line">df = pd.DataFrame(columns=[&quot;flower&quot;, &quot;price&quot;, &quot;description&quot;, &quot;reason&quot;]) # 先声明列名</span><br><span class="line"></span><br><span class="line">for flower, price in zip(flowers, prices):</span><br><span class="line">    # 根据提示准备模型的输入</span><br><span class="line">    input = prompt.format(flower_name=flower, price=price)</span><br><span class="line"></span><br><span class="line">    # 获取模型的输出</span><br><span class="line">    output = model.invoke(input)</span><br><span class="line">    </span><br><span class="line">    # 解析模型的输出（这是一个字典结构）</span><br><span class="line">    parsed_output = output_parser.parse(output)</span><br><span class="line"></span><br><span class="line">    # 在解析后的输出中添加“flower”和“price”</span><br><span class="line">    parsed_output[&#x27;flower&#x27;] = flower</span><br><span class="line">    parsed_output[&#x27;price&#x27;] = price</span><br><span class="line"></span><br><span class="line">    # 将解析后的输出添加到DataFrame中</span><br><span class="line">    df.loc[len(df)] = parsed_output  </span><br><span class="line"></span><br><span class="line"># 打印字典</span><br><span class="line">print(df.to_dict(orient=&#x27;records&#x27;))</span><br><span class="line"></span><br><span class="line"># 保存DataFrame到CSV文件</span><br><span class="line">df.to_csv(&quot;flowers_with_descriptions.csv&quot;, index=False)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[&#123;&#x27;flower&#x27;: &#x27;玫瑰&#x27;, &#x27;price&#x27;: &#x27;50&#x27;, &#x27;description&#x27;: &#x27;Luxuriate in the beauty of this 50 yuan rose, with its deep red petals and delicate aroma.&#x27;, &#x27;reason&#x27;: &#x27;This description emphasizes the elegance and beauty of the rose, which will be sure to draw attention.&#x27;&#125;, </span><br><span class="line">&#123;&#x27;flower&#x27;: &#x27;百合&#x27;, &#x27;price&#x27;: &#x27;30&#x27;, &#x27;description&#x27;: &#x27;30元的百合，象征着坚定的爱情，带给你的是温暖而持久的情感！&#x27;, &#x27;reason&#x27;: &#x27;百合是象征爱情的花，写出这样的描述能让顾客更容易感受到百合所带来的爱意。&#x27;&#125;, </span><br><span class="line">&#123;&#x27;flower&#x27;: &#x27;康乃馨&#x27;, &#x27;price&#x27;: &#x27;20&#x27;, &#x27;description&#x27;: &#x27;This beautiful carnation is the perfect way to show your love and appreciation. Its vibrant pink color is sure to brighten up any room!&#x27;, &#x27;reason&#x27;: &#x27;The description is short, clear and appealing, emphasizing the beauty and color of the carnation while also invoking a sense of love and appreciation.&#x27;&#125;]</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这段代码中，首先定义输出结构，我们希望模型生成的答案包含两部分：鲜花的描述文案（description）和撰写这个文案的原因（reason）。所以我们定义了一个名为 response_schemas 的列表，其中包含两个 ResponseSchema 对象，分别对应这两部分的输出。</p>
<p>根据这个列表，我通过 StructuredOutputParser.from_response_schemas 方法创建了一个输出解析器。</p>
<p>然后，我们通过输出解析器对象的 get_format_instructions() 方法获取输出的格式说明（format_instructions），再根据原始的字符串模板和输出解析器格式说明创建新的提示模板（这个模板就整合了输出解析结构信息）。再通过新的模板生成模型的输入，得到模型的输出。此时模型的输出结构将尽最大可能遵循我们的指示，以便于输出解析器进行解析。</p>
<p>对于每一个鲜花和价格组合，我们都用 output_parser.parse(output) 把模型输出的文案解析成之前定义好的数据格式，也就是一个 Python 字典，这个字典中包含了 description 和 reason 这两个字段的值。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">parsed_output</span><br><span class="line">&#123;&#x27;description&#x27;: &#x27;This 50-yuan rose is... feelings.&#x27;, &#x27;reason&#x27;: &#x27;The description is s...y emotion.&#x27;&#125;</span><br><span class="line">len(): 2</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>最后，把所有信息整合到一个 pandas DataFrame 对象中（需要安装 Pandas 库）。这个 DataFrame 对象中包含了 flower、price、description 和 reason 这四个字段的值。其中，description 和 reason 是由 output_parser 从模型的输出中解析出来的，flower 和 price 是我们自己添加的。</p>
<p>我们可以打印出 DataFrame 的内容，也方便地在程序中处理它，比如保存为下面的 CSV 文件。因为此时数据不再是模糊的、无结构的文本，而是结构清晰的有格式的数据。<strong>输出解析器在这个过程中的功劳很大</strong>。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8eb5d4eb72c2439397fba4d0fa5450c4~tplv-k3u1fbpfcp-jj-mark:2268:0:0:0:q75.awebp#?w=1032&amp;h=97&amp;s=6999&amp;e=png&amp;b=faf9f9" alt=""></p>
<p>到这里，我们今天的任务也就顺利完成了。</p>
<h2 id="总结时刻">总结时刻</h2>
<p>这样，你就从头到尾利用大模型开发出来了一个能够自动生成鲜花文案的应用程序！怎么样，是不是感觉和我们平时所做的基于 SQL 和数据库表以及固定业务逻辑的应用开发很不一样？</p>
<p>你看，每一次运行都有不同的结果，而我们完全不知道大模型下一次会给我们带来怎样的新东西。因此，基于大模型构建的应用可以说充满了创造力。</p>
<p>总结一下使用 LangChain 框架的好处，你会发现它有这样几个优势。</p>
<ol>
<li class="lvl-4">
<p>模板管理：在大型项目中，可能会有许多不同的提示模板，使用 LangChain 可以帮助你更好地管理这些模板，保持代码的清晰和整洁。</p>
</li>
<li class="lvl-4">
<p>变量提取和检查：LangChain 可以自动提取模板中的变量并进行检查，确保你没有忘记填充任何变量。</p>
</li>
<li class="lvl-4">
<p>模型切换：如果你想尝试使用不同的模型，只需要更改模型的名称就可以了，无需修改代码。</p>
</li>
<li class="lvl-4">
<p>输出解析：LangChain 的提示模板可以嵌入对输出格式的定义，以便在后续处理过程中比较方便地处理已经被格式化了的输出。</p>
</li>
</ol>
<p>在下节课中，我们将继续深入探索 LangChain 中的提示模板，看一看如何通过高质量的提示工程让模型创造出更为精准、更高质量的输出。</p>
<h2 id="思考题">思考题</h2>
<ol>
<li class="lvl-4">
<p>请你用自己的理解，简述 LangChain 调用大语言模型来做应用开发的优势。</p>
</li>
<li class="lvl-4">
<p>在上面的示例中，format_instructions，也就是输出格式是怎样用 output_parser 构建出来的，又是怎样传递到提示模板中的？</p>
</li>
<li class="lvl-4">
<p>加入了 partial_variables，也就是输出解析器指定的 format_instructions 之后的提示，为什么能够让模型生成结构化的输出？你可以打印出这个提示，一探究竟。</p>
</li>
<li class="lvl-4">
<p>使用输出解析器后，调用模型时有没有可能仍然得不到所希望的输出？也就是说，模型有没有可能仍然返回格式不够完美的输出？</p>
</li>
</ol>
<p>题目较多，可以选择性思考，期待在留言区看到你的分享。如果你觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。</p>
<h2 id="延伸阅读">延伸阅读</h2>
<ol>
<li class="lvl-4">
<p>吴恩达老师的<a href="https://link.juejin.cn/?target=https%3A%2F%2Flearn.deeplearning.ai%2Flogin%3Fredirect_course%3Dchatgpt-prompt-eng" title="https://learn.deeplearning.ai/login?redirect_course=chatgpt-prompt-eng">提示工程课程</a>，吴老师也有 LangChain 的简单介绍课程呦！网上也有这些课程的中文翻译版！</p>
</li>
<li class="lvl-4">
<p>LangChain 官方文档中，关于模型 I/O 的资料<a href="https://link.juejin.cn/?target=https%3A%2F%2Fpython.langchain.com%2Fdocs%2Fmodules%2Fmodel_io%2F" title="https://python.langchain.com/docs/modules/model_io/">在此</a>。</p>
</li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2024/12/08/%E7%BD%91%E9%A1%B5%E5%AF%BC%E5%85%A5/%E7%94%A8LangChain%E5%BF%AB%E9%80%9F%E6%9E%84%E5%BB%BA%E5%9F%BA%E4%BA%8E%E2%80%9C%E6%98%93%E9%80%9F%E9%B2%9C%E8%8A%B1%E2%80%9D%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E5%BA%93%E7%9A%84%E6%99%BA%E8%83%BD%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/" rel="prev" title="">
      <i class="fa fa-chevron-left"></i> 
    </a></div>
      <div class="post-nav-item">
    <a href="/2024/12/08/%E7%BD%91%E9%A1%B5%E5%AF%BC%E5%85%A5/%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90%EF%BC%9A%E9%80%9A%E8%BF%87RAG%E5%8A%A9%E5%8A%9B%E9%B2%9C%E8%8A%B1%E8%BF%90%E8%90%A5/" rel="next" title="">
       <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Model-I-O"><span class="nav-number">1.</span> <span class="nav-text">Model I&#x2F;O</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8F%90%E7%A4%BA%E6%A8%A1%E6%9D%BF"><span class="nav-number">2.</span> <span class="nav-text">提示模板</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.</span> <span class="nav-text">语言模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BE%93%E5%87%BA%E8%A7%A3%E6%9E%90"><span class="nav-number">4.</span> <span class="nav-text">输出解析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93%E6%97%B6%E5%88%BB"><span class="nav-number">5.</span> <span class="nav-text">总结时刻</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%9D%E8%80%83%E9%A2%98"><span class="nav-number">6.</span> <span class="nav-text">思考题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BB%B6%E4%BC%B8%E9%98%85%E8%AF%BB"><span class="nav-number">7.</span> <span class="nav-text">延伸阅读</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">听</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">653</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">48</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">听</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  

</body>
</html>
