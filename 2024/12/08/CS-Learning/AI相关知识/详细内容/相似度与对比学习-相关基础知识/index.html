<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
<link rel="stylesheet" href="/css/custom.css">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="为了理解双塔模型中“拉近”相关样本、“拉远”不相关样本的机制，以及背后的损失函数，必须掌握一些基础知识。以下是详细的介绍，包括神经网络的基本概念、损失函数以及对比学习等内容。 1. 神经网络基础知识 1.1 神经网络结构 神经网络是由一层层神经元组成的，每层神经元接收前一层的输出作为输入，并通过权重、偏置和激活函数进行变换，输出结果传递到下一层。常见的神经网络类型有：   全连接网络（Fully">
<meta property="og:type" content="article">
<meta property="og:title" content="O3xiaoyuhe">
<meta property="og:url" content="http://example.com/2024/12/08/CS-Learning/AI%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/%E8%AF%A6%E7%BB%86%E5%86%85%E5%AE%B9/%E7%9B%B8%E4%BC%BC%E5%BA%A6%E4%B8%8E%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0-%E7%9B%B8%E5%85%B3%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/index.html">
<meta property="og:site_name" content="O3xiaoyuhe">
<meta property="og:description" content="为了理解双塔模型中“拉近”相关样本、“拉远”不相关样本的机制，以及背后的损失函数，必须掌握一些基础知识。以下是详细的介绍，包括神经网络的基本概念、损失函数以及对比学习等内容。 1. 神经网络基础知识 1.1 神经网络结构 神经网络是由一层层神经元组成的，每层神经元接收前一层的输出作为输入，并通过权重、偏置和激活函数进行变换，输出结果传递到下一层。常见的神经网络类型有：   全连接网络（Fully">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2024-12-08T12:29:05.284Z">
<meta property="article:modified_time" content="2024-11-13T14:44:04.421Z">
<meta property="article:author" content="听">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2024/12/08/CS-Learning/AI%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/%E8%AF%A6%E7%BB%86%E5%86%85%E5%AE%B9/%E7%9B%B8%E4%BC%BC%E5%BA%A6%E4%B8%8E%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0-%E7%9B%B8%E5%85%B3%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title> | O3xiaoyuhe</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">O3xiaoyuhe</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/12/08/CS-Learning/AI%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/%E8%AF%A6%E7%BB%86%E5%86%85%E5%AE%B9/%E7%9B%B8%E4%BC%BC%E5%BA%A6%E4%B8%8E%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0-%E7%9B%B8%E5%85%B3%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="听">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="O3xiaoyuhe">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-12-08 20:29:05" itemprop="dateCreated datePublished" datetime="2024-12-08T20:29:05+08:00">2024-12-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-11-13 22:44:04" itemprop="dateModified" datetime="2024-11-13T22:44:04+08:00">2024-11-13</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>为了理解双塔模型中“拉近”相关样本、“拉远”不相关样本的机制，以及背后的损失函数，必须掌握一些基础知识。以下是详细的介绍，包括神经网络的基本概念、损失函数以及对比学习等内容。</p>
<h3 id="1-神经网络基础知识">1. <strong>神经网络基础知识</strong></h3>
<h4 id="1-1-神经网络结构">1.1 <strong>神经网络结构</strong></h4>
<p>神经网络是由一层层神经元组成的，每层神经元接收前一层的输出作为输入，并通过权重、偏置和激活函数进行变换，输出结果传递到下一层。常见的神经网络类型有：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>全连接网络（Fully Connected Network, FCN）</strong>：每个神经元与下一层所有神经元相连。</p>
</li>
<li class="lvl-2">
<p><strong>卷积神经网络（Convolutional Neural Networks, CNN）</strong>：主要用于图像处理，通过卷积操作提取局部特征。</p>
</li>
<li class="lvl-2">
<p><strong>递归神经网络（Recurrent Neural Networks, RNN）</strong>：主要用于处理序列数据（如文本），有记忆能力。</p>
</li>
<li class="lvl-2">
<p><strong>Transformer</strong>：一种并行计算高效的网络结构，适用于序列数据和多模态学习。</p>
</li>
</ul>
<h4 id="1-2-嵌入（Embedding）">1.2 <strong>嵌入（Embedding）</strong></h4>
<p>嵌入是将高维、稀疏的数据（如文本中的词）映射到一个低维的稠密向量空间。嵌入使得输入数据能够被神经网络处理，常用的嵌入方法包括：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>词嵌入（Word Embedding）</strong>：如Word2Vec、GloVe、BERT等模型，能够将词语转化为向量，捕捉词语的语义。</p>
</li>
<li class="lvl-2">
<p><strong>图像嵌入</strong>：通过卷积神经网络（如ResNet、EfficientNet）提取图像的特征向量。</p>
</li>
</ul>
<h3 id="2-损失函数（Loss-Function）">2. <strong>损失函数（Loss Function）</strong></h3>
<h4 id="2-1-定义">2.1 <strong>定义</strong></h4>
<p>损失函数用于衡量神经网络的预测输出与真实值之间的差异。神经网络的目标是通过训练最小化损失函数，以提升模型的性能。</p>
<h4 id="2-2-常见损失函数">2.2 <strong>常见损失函数</strong></h4>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>均方误差（Mean Squared Error, MSE）</strong>：用于回归任务，计算预测值与真实值之间的平方差。<br>
$$<br>
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y_i})^2<br>
$$<br>
其中，$y_i$ 是真实值，$\hat{y_i}$ 是预测值。</p>
</li>
<li class="lvl-2">
<p><strong>交叉熵损失（Cross-Entropy Loss）</strong>：用于分类任务，衡量预测的概率分布与真实标签的差异。<br>
$$<br>
\text{Cross-Entropy} = -\sum_{i} y_i \log(\hat{y_i})<br>
$$<br>
其中，$y_i$ 是真实标签的分布（通常是独热编码），$\hat{y_i}$ 是模型预测的概率分布。</p>
</li>
</ul>
<h3 id="3-相似度度量（Similarity-Measures）">3. <strong>相似度度量（Similarity Measures）</strong></h3>
<p>在双塔模型中，我们需要将图像和文本等不同模态的数据表示为向量，并比较这些向量的相似性。常见的相似度度量有：</p>
<h4 id="3-1-余弦相似度（Cosine-Similarity）">3.1 <strong>余弦相似度（Cosine Similarity）</strong></h4>
<p>余弦相似度衡量两个向量在空间中的夹角，取值范围为$[-1, 1]$。它用于衡量两个向量方向上的相似度，而不考虑向量的长度。<br>
$$<br>
\text{Cosine Similarity} = \frac{\mathbf{a} \cdot \mathbf{b}}{|\mathbf{a}| |\mathbf{b}|}<br>
$$<br>
其中，$\mathbf{a}$ 和 $\mathbf{b}$ 是两个向量，$\cdot$ 表示点积，$|\mathbf{a}|$ 表示向量的L2范数。</p>
<h4 id="3-2-欧几里得距离（Euclidean-Distance）">3.2 <strong>欧几里得距离（Euclidean Distance）</strong></h4>
<p>欧几里得距离衡量两个向量之间的直线距离，常用于测量两个点在空间中的距离。<br>
$$<br>
\text{Euclidean Distance} = |\mathbf{a} - \mathbf{b}| = \sqrt{\sum_{i=1}^{n} (a_i - b_i)^2}<br>
$$<br>
其中，$a_i$ 和 $b_i$ 是向量的分量。</p>
<h3 id="4-对比学习（Contrastive-Learning）">4. <strong>对比学习（Contrastive Learning）</strong></h3>
<p>对比学习是一种无监督学习或自监督学习的方法，其目标是让模型学习到相似样本之间的特征表示更加接近，不相似的样本之间的特征表示更加不同。对比学习的基本思想是在共享空间中通过拉近正样本对、拉远负样本对，来提升模型的表现。</p>
<h4 id="4-1-对比损失（Contrastive-Loss）">4.1 <strong>对比损失（Contrastive Loss）</strong></h4>
<p>对比损失用于在共享空间中进行正样本对的“拉近”和负样本对的“拉远”。对于一个输入对（anchor, positive, negative），其中<code>anchor</code>与<code>positive</code>是相关的样本，<code>negative</code>是无关样本，损失函数如下：<br>
$$<br>
\mathcal{L} = \frac{1}{N} \sum_{i=1}^{N} \left( d(a_i, p_i)^2 + \max(0, m - d(a_i, n_i))^2 \right)<br>
$$<br>
其中：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>$d(a_i, p_i)$ 是 <code>anchor</code> 和 <code>positive</code> 之间的距离。</p>
</li>
<li class="lvl-2">
<p>$d(a_i, n_i)$ 是 <code>anchor</code> 和 <code>negative</code> 之间的距离。</p>
</li>
<li class="lvl-2">
<p>$m$ 是一个定义正负样本之间最小间距的<strong>边界距离</strong>。</p>
</li>
</ul>
<p>该损失函数有两个目标：</p>
<ol>
<li class="lvl-3">
<p><strong>拉近</strong>相关样本对（<code>anchor</code> 和 <code>positive</code>），即让 $d(a_i, p_i)$ 尽可能小。</p>
</li>
<li class="lvl-3">
<p><strong>拉远</strong>无关样本对（<code>anchor</code> 和 <code>negative</code>），即让 $d(a_i, n_i)$ 尽可能大，并至少达到边界距离 $m$。</p>
</li>
</ol>
<h4 id="4-2-InfoNCE-Loss">4.2 <strong>InfoNCE Loss</strong></h4>
<p>InfoNCE损失是对比学习中的另一种损失函数，它通常用于<strong>自监督学习</strong>，帮助模型学习在共享空间中区分正负样本对。其公式为：<br>
$$<br>
\mathcal{L}<em>{\text{InfoNCE}} = - \log \frac{\exp(\text{sim}(\mathbf{a}, \mathbf{p}) / \tau)}{\sum</em>{i=0}^{K} \exp(\text{sim}(\mathbf{a}, \mathbf{n_i}) / \tau)}<br>
$$<br>
其中：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>$\mathbf{a}$ 是<code>anchor</code>样本，$\mathbf{p}$ 是正样本，$\mathbf{n_i}$ 是负样本。</p>
</li>
<li class="lvl-2">
<p>$\text{sim}(a, b)$ 表示<code>anchor</code>和正负样本之间的相似度，通常使用余弦相似度。</p>
</li>
<li class="lvl-2">
<p>$\tau$ 是温度参数，控制分布的平滑度。</p>
</li>
</ul>
<p><strong>目标</strong>是最大化正样本对的相似度，同时最小化负样本对的相似度。</p>
<h3 id="5-三元组损失（Triplet-Loss）">5. <strong>三元组损失（Triplet Loss）</strong></h3>
<p>三元组损失是一种用于度量学习的损失函数，它通过对样本的三元组（<code>anchor</code>，<code>positive</code>，<code>negative</code>）来训练模型，使得：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>anchor</code>与<code>positive</code>之间的距离比<code>anchor</code>与<code>negative</code>的距离小一个固定的<strong>边界距离</strong> $m$。</p>
</li>
</ul>
<p>损失函数的形式为：<br>
$$<br>
\mathcal{L}<em>{\text{triplet}} = \sum</em>{i=1}^{N} \max(0, d(\mathbf{a_i}, \mathbf{p_i}) - d(\mathbf{a_i}, \mathbf{n_i}) + m)<br>
$$<br>
其中：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>$d(\mathbf{a}, \mathbf{b})$ 是两个样本之间的距离（如欧几里得距离或余弦相似度）。</p>
</li>
<li class="lvl-2">
<p>$m$ 是边界距离，表示<code>positive</code>与<code>anchor</code>之间的距离应比<code>negative</code>与<code>anchor</code>的距离至少小 $m$。</p>
</li>
</ul>
<h3 id="6-度量学习（Metric-Learning）">6. <strong>度量学习（Metric Learning）</strong></h3>
<p>度量学习是构建距离或相似度度量的方法，使得语义相似的样本在向量空间中距离更近，语义不相似的样本距离更远。对比损失和三元组损失都是度量学习中的常用损失函数。</p>
<h3 id="总结">总结</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>神经网络基础</strong>：理解网络结构和嵌入的概念，能够处理不同模态的数据。</p>
</li>
<li class="lvl-2">
<p><strong>损失函数</strong>：掌握常见的损失函数如均方误差、交叉熵损</p>
</li>
</ul>
<p>失等。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>相似度度量</strong>：了解余弦相似度和欧几里得距离，用于比较不同模态的特征向量。</p>
</li>
<li class="lvl-2">
<p><strong>对比学习</strong>：通过对比损失、InfoNCE损失等方法，在共享空间中进行正负样本对的“拉近”和“拉远”。</p>
</li>
<li class="lvl-2">
<p><strong>度量学习</strong>：通过损失函数构建合理的相似度度量，确保模型能够有效地识别多模态数据的相关性。</p>
</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2024/12/08/CS-Learning/AI%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/%E8%AF%A6%E7%BB%86%E5%86%85%E5%AE%B9/%E5%A6%82%E6%9E%9C%E6%88%91%E6%83%B3%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AA%E5%A4%9A%E6%A8%A1%E6%80%81AI%E7%A8%8B%E5%BA%8F%EF%BC%8C%E7%BB%99%E5%87%BA%E4%B8%80%E4%BA%9B%E5%BB%BA%E8%AE%AE/" rel="prev" title="">
      <i class="fa fa-chevron-left"></i> 
    </a></div>
      <div class="post-nav-item">
    <a href="/2024/12/08/CS-Learning/ASP.NET%E5%AD%A6%E4%B9%A0/%E6%8E%A7%E4%BB%B6%E4%BD%BF%E7%94%A8/" rel="next" title="">
       <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="nav-number">1.</span> <span class="nav-text">1. 神经网络基础知识</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 神经网络结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-%E5%B5%8C%E5%85%A5%EF%BC%88Embedding%EF%BC%89"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 嵌入（Embedding）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%88Loss-Function%EF%BC%89"><span class="nav-number">2.</span> <span class="nav-text">2. 损失函数（Loss Function）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-%E5%AE%9A%E4%B9%89"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 定义</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-%E5%B8%B8%E8%A7%81%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 常见损失函数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E7%9B%B8%E4%BC%BC%E5%BA%A6%E5%BA%A6%E9%87%8F%EF%BC%88Similarity-Measures%EF%BC%89"><span class="nav-number">3.</span> <span class="nav-text">3. 相似度度量（Similarity Measures）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%EF%BC%88Cosine-Similarity%EF%BC%89"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 余弦相似度（Cosine Similarity）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E8%B7%9D%E7%A6%BB%EF%BC%88Euclidean-Distance%EF%BC%89"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 欧几里得距离（Euclidean Distance）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%EF%BC%88Contrastive-Learning%EF%BC%89"><span class="nav-number">4.</span> <span class="nav-text">4. 对比学习（Contrastive Learning）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-%E5%AF%B9%E6%AF%94%E6%8D%9F%E5%A4%B1%EF%BC%88Contrastive-Loss%EF%BC%89"><span class="nav-number">4.1.</span> <span class="nav-text">4.1 对比损失（Contrastive Loss）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-InfoNCE-Loss"><span class="nav-number">4.2.</span> <span class="nav-text">4.2 InfoNCE Loss</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-%E4%B8%89%E5%85%83%E7%BB%84%E6%8D%9F%E5%A4%B1%EF%BC%88Triplet-Loss%EF%BC%89"><span class="nav-number">5.</span> <span class="nav-text">5. 三元组损失（Triplet Loss）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0%EF%BC%88Metric-Learning%EF%BC%89"><span class="nav-number">6.</span> <span class="nav-text">6. 度量学习（Metric Learning）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">7.</span> <span class="nav-text">总结</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">听</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
        
          <span class="site-state-item-count">653</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">48</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">听</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  

</body>
</html>
